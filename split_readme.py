import re
import os
import subprocess

def split_readme():
    output_dir = 'docs'
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Read content from git history (previous commit) to recover full content
    try:
        content = subprocess.check_output(['git', 'show', 'HEAD^:README.md']).decode('utf-8')
        print("Successfully read content from git history.")
    except Exception as e:
        print(f"Error reading from git: {e}")
        return

    # Normalizing content headers just in case
    # The observed headers are "## ä¸€ã€", "## äºŒã€" etc.
    
    headers = [
        ("ä¸€ã€RAG æ ¸å¿ƒæµç¨‹", "01_core_principles.md"),
        ("äºŒã€è¯¦ç»†å®ç°æ­¥éª¤", "02_step_by_step_guide.md"),
        ("ä¸‰ã€é«˜çº§åŠŸèƒ½ä¸è¿›é˜¶", "03_advanced_rag.md"),
        ("å››ã€2026 å¹´ RAG å‰æ²¿æŠ€æœ¯", "04_cutting_edge_2026.md"),
        ("äº”ã€æ€»ç»“ï¼šRAG æ€§èƒ½è°ƒä¼˜ Checklist (2026 æ›´æ–°ç‰ˆ)", "05_performance_checklist.md"),
        ("å…­ã€æƒå¨å‚è€ƒä¸å®˜æ–¹æ–‡æ¡£é“¾æ¥", "06_references.md")
    ]
    
    intro_filename = "00_introduction.md"
    indices = []
    
    for header, filename in headers:
        # Use simple string search first as it is more robust if format is exact
        pattern = f"## {header}"
        pos = content.find(pattern)
        if pos != -1:
            indices.append((pos, header, filename))
        else:
            print(f"Warning: Header '{header}' not found!")

    indices.sort()
    
    if indices:
        intro_content = content[:indices[0][0]].strip()
        # Remove TOC if present
        intro_content = re.sub(r'## ğŸ“š ç›®å½•.*?(?=## ğŸš€)', '', intro_content, flags=re.DOTALL).strip()
        
        with open(os.path.join(output_dir, intro_filename), 'w', encoding='utf-8') as f:
            f.write(intro_content + "\n")
        print(f"Created {intro_filename}")

    for i in range(len(indices)):
        start_pos = indices[i][0]
        filename = indices[i][2]
        
        if i < len(indices) - 1:
            end_pos = indices[i+1][0]
            section_content = content[start_pos:end_pos].strip()
        else:
            section_content = content[start_pos:].strip()
            
        with open(os.path.join(output_dir, filename), 'w', encoding='utf-8') as f:
            f.write(section_content + "\n")
        print(f"Created {filename}")

    # Create new Index README.md (keeps existing index structure we planned)
    new_readme_content = f"""# LangChain RAG å®Œæ•´æŒ‡å— (2026 ç‰ˆ)

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ LangChain æ¡†æ¶ä»é›¶æ„å»ºä¸€ä¸ª RAG ç³»ç»Ÿã€‚ä¸ºæ–¹ä¾¿é˜…è¯»ä¸ç»´æŠ¤ï¼Œå·²å°†æ–‡æ¡£æ‹†åˆ†ä¸ºå¤šä¸ªç« èŠ‚ã€‚

## ğŸ“š ç›®å½•

- **[0. å¿«é€Ÿå…¥é—¨](./docs/00_introduction.md)**
  - æ ¸å¿ƒæ¦‚å¿µç®€ä»‹
  - 30ç§’ä¸Šæ‰‹æç®€ç¤ºä¾‹

- **[1. RAG æ ¸å¿ƒæµç¨‹](./docs/01_core_principles.md)**
  - Load -> Split -> Embed -> Store -> Retrieve -> Generate å…¨æµç¨‹å›¾è§£

- **[2. è¯¦ç»†å®ç°æ­¥éª¤](./docs/02_step_by_step_guide.md)**
  - åŒ…å«ç¯å¢ƒé…ç½®ã€æ–‡æ¡£åŠ è½½ã€åˆ†å‰²ã€å‘é‡åŒ–ç­‰å®Œæ•´ä»£ç å®ç°

- **[3. é«˜çº§åŠŸèƒ½ä¸è¿›é˜¶](./docs/03_advanced_rag.md)**
  - è®°å¿†å¯¹è¯ (Conversational RAG)
  - æ··åˆæ£€ç´¢ (Hybrid Search)
  - é‡æ’åº (Reranking)
  - ä»£ç†å‹ RAG (Agentic RAG) & LangGraph å·¥ä½œæµ
  - RAG è¯„ä¼° (Ragas & LangSmith)

- **[4. 2026 å‰æ²¿æŠ€æœ¯](./docs/04_cutting_edge_2026.md)**
  - GraphRAG
  - Corrective RAG (CRAG)
  - å¤šæ¨¡æ€ RAG
  - LangGraph 2.0 å±•æœ›

- **[5. æ€§èƒ½è°ƒä¼˜ Checklist](./docs/05_performance_checklist.md)**
  - ç”Ÿäº§ç¯å¢ƒæ’æŸ¥æ¸…å•

- **[6. å‚è€ƒèµ„æº](./docs/06_references.md)**
  - å®˜æ–¹æ–‡æ¡£ä¸æƒå¨åšå®¢é“¾æ¥

---

*ä¸Šæ¬¡æ›´æ–°: 2026-01-13*
"""

    with open('README.md', 'w', encoding='utf-8') as f:
        f.write(new_readme_content)
    print("Updated README.md with new index.")

if __name__ == "__main__":
    split_readme()


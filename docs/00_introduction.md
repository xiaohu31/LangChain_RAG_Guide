# LangChain RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) å®ç°å®Œæ•´æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ LangChain æ¡†æ¶ä»é›¶æ„å»ºä¸€ä¸ª RAG ç³»ç»Ÿã€‚æ¶µç›–äº†ä»æ–‡æ¡£åŠ è½½ã€åˆ‡åˆ†ã€å‘é‡åŒ–ã€å­˜å‚¨åˆ°æ£€ç´¢å’Œç”Ÿæˆçš„å…¨æµç¨‹ï¼Œå¹¶é™„å¸¦äº†è¯¦ç»†çš„ä»£ç æ³¨é‡Šã€‚

---

## ğŸš€ å¿«é€Ÿå…¥é—¨ (30ç§’ä¸Šæ‰‹)

ä»¥ä¸‹æ˜¯ä¸€ä¸ªæœ€ç®€ RAG ç¤ºä¾‹ï¼Œå¸®åŠ©ä½ å¿«é€Ÿç†è§£æ ¸å¿ƒæµç¨‹ï¼š

```python
# å®‰è£…ä¾èµ–: pip install langchain langchain-openai langchain-community chromadb langchain_text_splitters

from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# 1. åŠ è½½æ–‡æ¡£
docs = TextLoader("./your_document.txt").load()

# 2. åˆ†å‰²æ–‡æ¡£
splits = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50).split_documents(docs)

# 3. åˆ›å»ºå‘é‡åº“
vectordb = Chroma.from_documents(splits, OpenAIEmbeddings())

# 4. æ„å»º RAG é“¾
prompt = ChatPromptTemplate.from_template("æ ¹æ®ä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜:\n{context}\n\né—®é¢˜: {question}")
rag_chain = (
    {"context": vectordb.as_retriever() | (lambda docs: "\n".join(d.page_content for d in docs)), 
     "question": RunnablePassthrough()}
    | prompt | ChatOpenAI(model="gpt-4o-mini") | StrOutputParser()
)

# 5. æé—®
print(rag_chain.invoke("æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ"))
```

---
